\section{Introduction}

The exponential growth of social media platforms has led to unprecedented levels of online engagement, but it has also introduced significant challenges, particularly concerning the prevalence of toxic comments. Toxic comments have become a major issue, characterized by rudeness, disrespect, and a tendency to disrupt or drive participants out of discussions. \cite{Androcec2020}

Their presence exacerbates the problem of cyberbullying, with studies showing that approximately 15\% of teens have experienced online bullying, which is strongly linked to psychological problems such as depression and anxiety. \cite{Zaheri2020} 

Effective moderation is essential, but manual approaches are not scalable given the sheer volume of user-generated content. This makes automated toxic comment classification a critical task for ensuring safer and more inclusive online spaces.

Machine learning (ML) and deep learning methods have emerged as promising tools to tackle this problem. Classical approaches like naive Bayes and support vector machines (SVMs) have been employed as benchmarks, while more sophisticated models such as convolutional neural networks (CNNs), recurrent neural networks (RNNs), long short-term memory networks (LSTMs), and BERT have demonstrated considerable success. \cite{Androcec2020}

The focus of this report is on achieving the first milestone in this project, which involves implementing baseline methods for toxic comment classification. This milestone is designed to familiarize us with the datasets, establish performance baselines, create a prototype BERT model, and identify suitable evaluation metrics. The subsequent sections of this report will address these objectives in the order outlined, providing a foundation for further advancements in the project.