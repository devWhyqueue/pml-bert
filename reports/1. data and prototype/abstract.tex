\begin{abstract}
This project aims to fine-tune BERT for toxic comment classification, addressing the challenges of identifying harmful online content. Baseline methods such as logistic regression, support vector machines, and random forest were implemented and evaluated on the Civil Comments dataset as part of this milestone. These methods served as a reference for understanding the dataset and establishing performance benchmarks for BERT. Key findings revealed that logistic regression with preprocessing performed best among the baselines, achieving high-weighted F1 and AUC-ROC scores. However, precision and recall for the minority toxic class (C1) remained suboptimal. The dataset's significant class imbalance was identified as the primary challenge, emphasizing the need for advanced methods to improve performance. Future work will involve extending baseline evaluations to additional datasets (e.g., Jigsaw Toxicity and SST-2) and fine-tuning BERT for comparative analysis. The code for this project is publicly available on GitHub\footnote{\url{https://github.com/devWhyqueue/pml-bert}}.
\end{abstract}
