data:
  train:
    - identifier: 'wikimedia/wikipedia'
      short: 'wikipedia'
      name: '20231101.en'
      split: 'train'
    - identifier: 'manu/project_gutenberg'
      short: 'project_gutenberg'
      name: null
      split: 'en'
  finetuning:
    - identifier: 'google/civil_comments'
      short: 'civil_comments'
      name: null
      split: null
    - identifier: 'google/jigsaw_toxicity_pred'
      short: 'jigsaw_toxicity_pred'
      name: null
      split: null
      config_kwargs:
        data_dir: 'data/jigsaw_toxicity_pred'
    - identifier: 'stanfordnlp/sst2'
      short: 'sst2'
      name: null
      split: null


model:
  hidden_size: 768
  num_layers: 12
  num_heads: 12
  max_position_embeddings: 512
  vocab_size: 30522

finetuning:
  batch_size: 32
  learning_rate: 0.00001
  device: "cpu"
  num_epochs: 3
  n_train: 1000
  n_test: 100
